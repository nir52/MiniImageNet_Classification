{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\torch_gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, ProgressBar, LearningRateMonitor, Timer, StochasticWeightAveraging, TQDMProgressBar, Callback\n",
    "from pytorch_lightning.callbacks.callback import Callback\n",
    "from pytorch_lightning.profilers import SimpleProfiler, AdvancedProfiler\n",
    "from pytorch_lightning.utilities import seed\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from optuna.integration import PyTorchLightningPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1.post0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting dataset path\n",
    "path = \"E:\\\\mini_ImageNet\\\\archive\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.4764, 0.4491, 0.4001]\n",
      "Std: [0.2264, 0.2224, 0.2212]\n"
     ]
    }
   ],
   "source": [
    "#Using the previously calculated values (first notebook) of mean and std of the images in this dataset\n",
    "mean = [0.4764, 0.4491, 0.4001]\n",
    "std = [0.2264, 0.2224, 0.2212]\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.Resize(224),             # resize shortest side to 224 pixels\n",
    "        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    \n",
    "        transforms.RandomRotation(20),      # rotate +/- 20 degrees\n",
    "        transforms.RandomHorizontalFlip(p=0.25),  # flip 24% of images\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, \n",
    "                                                       saturation=0.2)], p=0.5), # jitters by +/- given value\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.7))], p=0.3)\n",
    "    ])\n",
    "#https://docs.pytorch.org/vision/main/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting class names from the folder names of images\n",
    "class_names=sorted(os.listdir(path))\n",
    "class_names = ['_'.join(c.split('_')[:-1]) for c in class_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, root_dir, batch_size, transform):\n",
    "        super().__init__()\n",
    "        self.data_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.num_w = 4\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        full_dataset = datasets.ImageFolder(root=self.data_dir, transform=self.transform)\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = int(0.2 * len(full_dataset))\n",
    "        self.train_dataset, self.val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, \n",
    "                         num_workers=self.num_w, persistent_workers=True)        \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, \n",
    "                         num_workers=self.num_w, persistent_workers=True)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(pl.LightningModule):\n",
    "    def __init__(self, trial, num_classes=50):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Trial suggestions\n",
    "        c1 = trial.suggest_categorical(\"conv1_out\", [16, 32, 64])\n",
    "        c2 = trial.suggest_categorical(\"conv2_out\", [32, 64, 96])\n",
    "        c3 = trial.suggest_categorical(\"conv3_out\", [64, 128])\n",
    "        c4 = trial.suggest_categorical(\"conv4_out\", [64, 96, 128, 0])\n",
    "        ksize = trial.suggest_categorical(\"kernel_size\", [3, 5])\n",
    "\n",
    "        fc1_size = trial.suggest_categorical(\"fc1_size\", [256, 512])\n",
    "        fc2_size = trial.suggest_categorical(\"fc2_size\", [128, 256, 512, 0])\n",
    "        fc3_size = trial.suggest_categorical(\"fc3_size\", [64, 128, 256, 0])\n",
    "\n",
    "        # Constraint 1: Avoid both conv3 and conv4 having 128 channels\n",
    "        if c3 == 128 and c4 == 128:\n",
    "            raise optuna.TrialPruned(\"Avoiding trial: conv3 and conv4 both 128\")\n",
    "        \n",
    "        # Constraint 2: Avoid both fc1 and fc2 being 512\n",
    "        if fc1_size == 512 and fc2_size == 512:\n",
    "            raise optuna.TrialPruned(\"Avoiding trial: fc1 and fc2 both 512\")\n",
    "\n",
    "        # Constraint 3: Avoid fc2=0 and fc3>0\n",
    "        if fc2_size == 0 and fc3_size>0:\n",
    "            raise optuna.TrialPruned(\"Avoiding trial: fc2=0 and fc3>0\")\n",
    "        \n",
    "        \n",
    "        dropout1 = trial.suggest_float(\"dropout1\", 0.2, 0.5)\n",
    "        dropout2 = trial.suggest_float(\"dropout2\", 0.2, 0.5)\n",
    "        dropout3 = trial.suggest_float(\"dropout3\", 0.2, 0.5)\n",
    "        \n",
    "        self.learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-3, log=True)\n",
    "        \n",
    "        act_fn = nn.LeakyReLU(0.05)\n",
    "        \n",
    "        # Layers\n",
    "        conv_layers = [\n",
    "            nn.Conv2d(3, c1, kernel_size=ksize, padding=ksize // 2),\n",
    "            nn.BatchNorm2d(c1),\n",
    "            act_fn,\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(c1, c2, kernel_size=ksize, padding=ksize // 2),\n",
    "            nn.BatchNorm2d(c2),\n",
    "            act_fn,\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(c2, c3, kernel_size=ksize, padding=ksize // 2),\n",
    "            nn.BatchNorm2d(c3),\n",
    "            act_fn,\n",
    "            nn.MaxPool2d(2),\n",
    "        ]\n",
    "        \n",
    "        # Optionally add conv4\n",
    "        if c4 > 0:\n",
    "            conv_layers.extend([\n",
    "                nn.Conv2d(c3, c4, kernel_size=ksize, padding=ksize // 2),\n",
    "                nn.BatchNorm2d(c4),\n",
    "                act_fn,\n",
    "                nn.MaxPool2d(2),\n",
    "            ])\n",
    "            conv_out = c4\n",
    "        else:\n",
    "            conv_out = c3\n",
    "        \n",
    "        # Add flatten after convs\n",
    "        conv_layers.append(nn.Flatten())\n",
    "        \n",
    "        # Wrap as Sequential\n",
    "        self.model = nn.Sequential(*conv_layers)\n",
    "        \n",
    "        \n",
    "        # Use dummy input to calculate flattened output size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
    "            n_features = self.model(dummy_input).shape[1]\n",
    "        \n",
    "        layers = [\n",
    "            nn.Linear(n_features, fc1_size),\n",
    "            nn.BatchNorm1d(fc1_size),\n",
    "            act_fn,\n",
    "            nn.Dropout(dropout1),\n",
    "        ]\n",
    "\n",
    "        final_in = fc1_size\n",
    "\n",
    "        if fc2_size > 0:\n",
    "            layers.extend([\n",
    "                nn.Linear(fc1_size, fc2_size),\n",
    "                nn.BatchNorm1d(fc2_size),\n",
    "                act_fn,\n",
    "                nn.Dropout(dropout2)\n",
    "            ])\n",
    "            final_in = fc2_size\n",
    "\n",
    "        if fc3_size > 0:\n",
    "            layers.extend([\n",
    "                nn.Linear(final_in, fc3_size),\n",
    "                nn.BatchNorm1d(fc3_size),\n",
    "                act_fn,\n",
    "                nn.Dropout(dropout3)\n",
    "            ])\n",
    "            final_in = fc3_size\n",
    "\n",
    "        self.head = nn.Sequential(*layers)\n",
    "        self.output = nn.Linear(final_in, num_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.head(x)\n",
    "        return self.output(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the Validation DataLoader progress bar between epochs\n",
    "class MinimalProgressBar(TQDMProgressBar):\n",
    "    def init_validation_tqdm(self):\n",
    "        # Return a dummy tqdm with no visible output to disable validation progress bar\n",
    "        # Set total=0 to avoid progress display\n",
    "        return tqdm(disable=True)\n",
    "\n",
    "    def init_test_tqdm(self):\n",
    "        # Same for test dataloader\n",
    "        return tqdm(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearCacheCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedPruningCallback(PyTorchLightningPruningCallback, Callback):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # Only start pruning after 3 epochs\n",
    "        if trainer.current_epoch < 2:\n",
    "            return  # Skip pruning\n",
    "\n",
    "        # Call the original pruning logic\n",
    "        super().on_validation_end(trainer, pl_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    try:\n",
    "        model = CNNModel(trial)\n",
    "        datamodule = DataModule(root_dir=path, batch_size=32, transform=transform)\n",
    "        datamodule.setup()\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            logger=False,\n",
    "            max_epochs=15,\n",
    "            enable_checkpointing=False,\n",
    "            callbacks=[MinimalProgressBar(), \n",
    "                       FixedPruningCallback(trial, monitor=\"val_loss\"),\n",
    "                       ClearCacheCallback()],\n",
    "        )\n",
    "        \n",
    "        trainer.fit(model, datamodule)\n",
    "        return trainer.callback_metrics[\"val_loss\"].item()\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        if \"DefaultCPUAllocator\" in str(e) or \"out of memory\" in str(e):\n",
    "            print(f\"Trial {trial.number} failed due to memory error.\")\n",
    "            return float('inf')\n",
    "        raise  e\n",
    "    \n",
    "    finally:\n",
    "        if 'model' in locals():\n",
    "            del model\n",
    "        if 'trainer' in locals():\n",
    "            del trainer\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 23:45:39,309] A new study created in memory with name: no-name-598ea8c7-84fe-40b8-8b17-680ccdcccf04\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 566 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "10.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 M    Total params\n",
      "41.652    Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:26<00:00,  5.10it/s, train_loss=1.950, train_acc=0.438, val_loss=2.270, val_acc=0.381]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:27<00:00,  5.10it/s, train_loss=1.950, train_acc=0.438, val_loss=2.270, val_acc=0.381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 00:23:33,501] Trial 0 finished with value: 2.2656238079071045 and parameters: {'conv1_out': 32, 'conv2_out': 64, 'conv3_out': 128, 'conv4_out': 96, 'kernel_size': 5, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 256, 'dropout1': 0.26199962483529415, 'dropout2': 0.2682733693525525, 'dropout3': 0.32604225068418363, 'learning_rate': 0.00011542742572824158}. Best is trial 0 with value: 2.2656238079071045.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 168 K  | train\n",
      "1 | head   | Sequential | 51.4 M | train\n",
      "2 | output | Linear     | 25.7 K | train\n",
      "----------------------------------------------\n",
      "51.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "51.6 M    Total params\n",
      "206.304   Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:26<00:00,  5.13it/s, train_loss=2.570, train_acc=0.344, val_loss=2.280, val_acc=0.394]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:26<00:00,  5.12it/s, train_loss=2.570, train_acc=0.344, val_loss=2.280, val_acc=0.394]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 01:01:00,784] Trial 1 finished with value: 2.2806146144866943 and parameters: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 0, 'kernel_size': 3, 'fc1_size': 512, 'fc2_size': 0, 'fc3_size': 0, 'dropout1': 0.3065172188662013, 'dropout2': 0.22344681479126122, 'dropout3': 0.3720363418504191, 'learning_rate': 0.00021900524281016052}. Best is trial 0 with value: 2.2656238079071045.\n",
      "[I 2025-06-10 01:01:00,934] Trial 2 pruned. Avoiding trial: fc2=0 and fc3>0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 312 K  | train\n",
      "1 | head   | Sequential | 51.5 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "51.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "51.8 M    Total params\n",
      "207.357   Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:33<00:00,  4.90it/s, train_loss=2.410, train_acc=0.406, val_loss=2.220, val_acc=0.410]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:33<00:00,  4.89it/s, train_loss=2.410, train_acc=0.406, val_loss=2.220, val_acc=0.410]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 01:39:55,678] Trial 3 finished with value: 2.2202320098876953 and parameters: {'conv1_out': 64, 'conv2_out': 64, 'conv3_out': 128, 'conv4_out': 0, 'kernel_size': 5, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.23779195094934324, 'dropout2': 0.26330769965130246, 'dropout3': 0.21606656009558822, 'learning_rate': 0.0008472593038299467}. Best is trial 3 with value: 2.2202320098876953.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 76.1 K | train\n",
      "1 | head   | Sequential | 3.5 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.262    Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:34<00:00,  4.84it/s, train_loss=2.790, train_acc=0.281, val_loss=2.390, val_acc=0.354]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:34<00:00,  4.84it/s, train_loss=2.790, train_acc=0.281, val_loss=2.390, val_acc=0.354]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 02:19:29,935] Trial 4 finished with value: 2.3927574157714844 and parameters: {'conv1_out': 64, 'conv2_out': 32, 'conv3_out': 64, 'conv4_out': 64, 'kernel_size': 3, 'fc1_size': 256, 'fc2_size': 512, 'fc3_size': 256, 'dropout1': 0.3575261683718324, 'dropout2': 0.4811557721410208, 'dropout3': 0.46839249970500096, 'learning_rate': 0.00037689752416906574}. Best is trial 3 with value: 2.2202320098876953.\n",
      "[I 2025-06-10 02:19:30,098] Trial 5 pruned. Avoiding trial: fc1 and fc2 both 512\n",
      "[I 2025-06-10 02:19:30,223] Trial 6 pruned. Avoiding trial: fc2=0 and fc3>0\n",
      "[I 2025-06-10 02:19:30,343] Trial 7 pruned. Avoiding trial: conv3 and conv4 both 128\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 168 K  | train\n",
      "1 | head   | Sequential | 51.5 M | train\n",
      "2 | output | Linear     | 6.5 K  | train\n",
      "----------------------------------------------\n",
      "51.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "51.7 M    Total params\n",
      "206.887   Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:30<00:00,  4.98it/s, train_loss=2.220, train_acc=0.281, val_loss=2.580, val_acc=0.307]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:30<00:00,  4.97it/s, train_loss=2.220, train_acc=0.281, val_loss=2.580, val_acc=0.307]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 02:58:01,268] Trial 8 finished with value: 2.5786826610565186 and parameters: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 0, 'kernel_size': 3, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 128, 'dropout1': 0.2561433494543277, 'dropout2': 0.4511093232775636, 'dropout3': 0.3285082065819789, 'learning_rate': 0.00044749807171203085}. Best is trial 3 with value: 2.2202320098876953.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 210 K  | train\n",
      "1 | head   | Sequential | 6.6 M  | train\n",
      "2 | output | Linear     | 3.2 K  | train\n",
      "----------------------------------------------\n",
      "6.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.8 M     Total params\n",
      "27.144    Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████| 750/750 [02:30<00:00,  4.97it/s, train_loss=3.480, train_acc=0.156, val_loss=3.250, val_acc=0.161]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 03:06:08,901] Trial 9 pruned. Trial was pruned at epoch 2.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 116 K  | train\n",
      "1 | head   | Sequential | 25.7 M | train\n",
      "2 | output | Linear     | 6.5 K  | train\n",
      "----------------------------------------------\n",
      "25.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.8 M    Total params\n",
      "103.390   Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████| 750/750 [05:37<00:00,  2.22it/s, train_loss=3.480, train_acc=0.156, val_loss=3.250, val_acc=0.161]\n",
      "Epoch 4: 100%|█████| 750/750 [02:29<00:00,  5.02it/s, train_loss=2.330, train_acc=0.406, val_loss=2.820, val_acc=0.253]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 03:19:34,992] Trial 10 pruned. Trial was pruned at epoch 4.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 566 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "10.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 M    Total params\n",
      "41.652    Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████| 750/750 [05:29<00:00,  2.28it/s, train_loss=2.330, train_acc=0.406, val_loss=2.820, val_acc=0.253]\n",
      "Epoch 2: 100%|████| 750/750 [02:28<00:00,  5.04it/s, train_loss=3.310, train_acc=0.0938, val_loss=3.050, val_acc=0.211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 03:27:53,298] Trial 11 pruned. Trial was pruned at epoch 2.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 566 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "10.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.3 M    Total params\n",
      "41.386    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████| 750/750 [05:39<00:00,  2.21it/s, train_loss=3.310, train_acc=0.0938, val_loss=3.050, val_acc=0.211]\n",
      "Epoch 14: 100%|████| 750/750 [02:30<00:00,  4.99it/s, train_loss=1.880, train_acc=0.500, val_loss=2.080, val_acc=0.432]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:30<00:00,  4.98it/s, train_loss=1.880, train_acc=0.500, val_loss=2.080, val_acc=0.432]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 04:06:36,860] Trial 12 finished with value: 2.0809056758880615 and parameters: {'conv1_out': 32, 'conv2_out': 64, 'conv3_out': 128, 'conv4_out': 96, 'kernel_size': 5, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.3044326250278261, 'dropout2': 0.3024301614756779, 'dropout3': 0.2936390586560871, 'learning_rate': 0.0009792923216661608}. Best is trial 12 with value: 2.0809056758880615.\n",
      "[I 2025-06-10 04:06:36,994] Trial 13 pruned. Avoiding trial: conv3 and conv4 both 128\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 232 K  | train\n",
      "1 | head   | Sequential | 25.8 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "26.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.0 M    Total params\n",
      "104.009   Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████| 750/750 [02:30<00:00,  4.99it/s, train_loss=3.090, train_acc=0.156, val_loss=2.960, val_acc=0.225]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 04:14:40,599] Trial 14 pruned. Trial was pruned at epoch 2.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 773 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "10.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.6 M    Total params\n",
      "42.216    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████| 750/750 [05:33<00:00,  2.25it/s, train_loss=3.090, train_acc=0.156, val_loss=2.960, val_acc=0.225]\n",
      "Epoch 14: 100%|████| 750/750 [02:29<00:00,  5.02it/s, train_loss=2.210, train_acc=0.406, val_loss=2.070, val_acc=0.435]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:29<00:00,  5.02it/s, train_loss=2.210, train_acc=0.406, val_loss=2.070, val_acc=0.435]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 04:52:57,670] Trial 15 finished with value: 2.0743117332458496 and parameters: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 96, 'kernel_size': 5, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.29883094495102974, 'dropout2': 0.3061692504447138, 'dropout3': 0.2669174336821721, 'learning_rate': 0.0006189829762524606}. Best is trial 15 with value: 2.0743117332458496.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 694 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "41.899    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████| 750/750 [02:25<00:00,  5.14it/s, train_loss=2.680, train_acc=0.219, val_loss=2.660, val_acc=0.288]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 05:08:08,456] Trial 16 pruned. Trial was pruned at epoch 5.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 773 K  | train\n",
      "1 | head   | Sequential | 9.7 M  | train\n",
      "2 | output | Linear     | 6.5 K  | train\n",
      "----------------------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "41.927    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████| 750/750 [05:26<00:00,  2.30it/s, train_loss=2.680, train_acc=0.219, val_loss=2.660, val_acc=0.288]\n",
      "Epoch 2: 100%|█████| 750/750 [02:29<00:00,  5.02it/s, train_loss=2.700, train_acc=0.281, val_loss=2.970, val_acc=0.216]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 05:16:27,627] Trial 17 pruned. Trial was pruned at epoch 2.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 694 K  | train\n",
      "1 | head   | Sequential | 5.0 M  | train\n",
      "2 | output | Linear     | 3.2 K  | train\n",
      "----------------------------------------------\n",
      "5.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 M     Total params\n",
      "22.725    Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████| 750/750 [05:31<00:00,  2.26it/s, train_loss=2.700, train_acc=0.281, val_loss=2.970, val_acc=0.216]\n",
      "Epoch 2: 100%|█████| 750/750 [02:29<00:00,  5.01it/s, train_loss=3.020, train_acc=0.188, val_loss=3.160, val_acc=0.173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 05:24:49,099] Trial 18 pruned. Trial was pruned at epoch 2.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 655 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 6.5 K  | train\n",
      "----------------------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "41.847    Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████| 750/750 [05:29<00:00,  2.28it/s, train_loss=3.020, train_acc=0.188, val_loss=3.160, val_acc=0.173]\n",
      "Epoch 2: 100%|████| 750/750 [02:27<00:00,  5.10it/s, train_loss=3.300, train_acc=0.0625, val_loss=3.040, val_acc=0.211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 05:33:02,387] Trial 19 pruned. Trial was pruned at epoch 2.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 773 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "10.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.6 M    Total params\n",
      "42.216    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████| 750/750 [05:27<00:00,  2.29it/s, train_loss=3.300, train_acc=0.0625, val_loss=3.040, val_acc=0.211]\n",
      "Epoch 3: 100%|█████| 750/750 [02:29<00:00,  5.02it/s, train_loss=2.960, train_acc=0.156, val_loss=2.850, val_acc=0.242]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 05:43:50,594] Trial 20 pruned. Trial was pruned at epoch 3.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 312 K  | train\n",
      "1 | head   | Sequential | 51.5 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "51.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "51.8 M    Total params\n",
      "207.357   Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████| 750/750 [05:22<00:00,  2.33it/s, train_loss=2.960, train_acc=0.156, val_loss=2.850, val_acc=0.242]\n",
      "Epoch 8: 100%|█████| 750/750 [02:22<00:00,  5.27it/s, train_loss=2.590, train_acc=0.375, val_loss=2.490, val_acc=0.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 06:06:09,819] Trial 21 pruned. Trial was pruned at epoch 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████| 750/750 [02:23<00:00,  5.23it/s, train_loss=2.590, train_acc=0.375, val_loss=2.490, val_acc=0.330]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 06:06:31,332] Trial 22 pruned. Avoiding trial: conv3 and conv4 both 128\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 159 K  | train\n",
      "1 | head   | Sequential | 51.5 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "51.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "51.7 M    Total params\n",
      "206.742   Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████| 750/750 [02:27<00:00,  5.09it/s, train_loss=2.580, train_acc=0.281, val_loss=2.870, val_acc=0.248]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 06:16:55,523] Trial 23 pruned. Trial was pruned at epoch 3.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 620 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "10.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 M    Total params\n",
      "41.601    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████| 750/750 [05:30<00:00,  2.27it/s, train_loss=2.580, train_acc=0.281, val_loss=2.870, val_acc=0.248]\n",
      "Epoch 14: 100%|████| 750/750 [02:25<00:00,  5.15it/s, train_loss=1.800, train_acc=0.406, val_loss=2.080, val_acc=0.429]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:25<00:00,  5.15it/s, train_loss=1.800, train_acc=0.406, val_loss=2.080, val_acc=0.429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 06:54:15,061] Trial 24 finished with value: 2.0770821571350098 and parameters: {'conv1_out': 64, 'conv2_out': 64, 'conv3_out': 128, 'conv4_out': 96, 'kernel_size': 5, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.29230946924019013, 'dropout2': 0.2356787685263997, 'dropout3': 0.24057023643387784, 'learning_rate': 0.0007884227357931359}. Best is trial 15 with value: 2.0743117332458496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 96, 'kernel_size': 5, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.29883094495102974, 'dropout2': 0.3061692504447138, 'dropout3': 0.2669174336821721, 'learning_rate': 0.0006189829762524606}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=25, timeout=54000)\n",
    "print(\"Best trial:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trial data to optuna_trials_log.csv\n"
     ]
    }
   ],
   "source": [
    "# Collect all trials into a list of dicts\n",
    "rows = []\n",
    "for trial in study.trials:\n",
    "    row = {\n",
    "        \"trial_number\": trial.number,\n",
    "        \"value\": trial.value,\n",
    "    }\n",
    "    # Add all hyperparameters\n",
    "    row.update(trial.params)\n",
    "    \n",
    "    # Add intermediate values (e.g., val_loss at each epoch)\n",
    "    for step, intermediate in trial.intermediate_values.items():\n",
    "        row[f\"epoch_{step}_val_loss\"] = intermediate\n",
    "    \n",
    "    rows.append(row)\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"optuna_trials_log.csv\", index=False)\n",
    "print(\"Saved trial data to optuna_trials_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_env",
   "language": "python",
   "name": "torch_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
