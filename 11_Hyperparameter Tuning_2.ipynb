{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\torch_gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, ProgressBar, LearningRateMonitor, Timer, StochasticWeightAveraging, TQDMProgressBar, Callback\n",
    "from pytorch_lightning.callbacks.callback import Callback\n",
    "from pytorch_lightning.profilers import SimpleProfiler, AdvancedProfiler\n",
    "from pytorch_lightning.utilities import seed\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from optuna.integration import PyTorchLightningPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1.post0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting dataset path\n",
    "path = \"E:\\\\mini_ImageNet\\\\archive\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.4764, 0.4491, 0.4001]\n",
      "Std: [0.2264, 0.2224, 0.2212]\n"
     ]
    }
   ],
   "source": [
    "#Hardcoding the mean and std values; these were calculated in nb 1\n",
    "mean = [0.4764, 0.4491, 0.4001]\n",
    "std = [0.2264, 0.2224, 0.2212]\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.Resize(224),             # resize shortest side to 224 pixels\n",
    "        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    \n",
    "        transforms.RandomRotation(20),      # rotate +/- 20 degrees\n",
    "        transforms.RandomHorizontalFlip(p=0.25),  # flip 24% of images\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, \n",
    "                                                       saturation=0.2)], p=0.5), # jitters by +/- given value\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.7))], p=0.3)\n",
    "    ])\n",
    "#https://docs.pytorch.org/vision/main/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting class names from the folder names of images\n",
    "class_names=sorted(os.listdir(path))\n",
    "class_names = ['_'.join(c.split('_')[:-1]) for c in class_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, root_dir, batch_size, transform):\n",
    "        super().__init__()\n",
    "        self.data_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.num_w = 4\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        full_dataset = datasets.ImageFolder(root=self.data_dir, transform=self.transform)\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = int(0.2 * len(full_dataset))\n",
    "        self.train_dataset, self.val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, \n",
    "                         num_workers=self.num_w, persistent_workers=True)        \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, \n",
    "                         num_workers=self.num_w, persistent_workers=True)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(pl.LightningModule):\n",
    "    def __init__(self, trial, num_classes=50):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Trial suggestions\n",
    "        c1 = trial.suggest_categorical(\"conv1_out\", [64])\n",
    "        c2 = trial.suggest_categorical(\"conv2_out\", [96])\n",
    "        c3 = trial.suggest_categorical(\"conv3_out\", [128])\n",
    "        c4 = trial.suggest_categorical(\"conv4_out\", [96, 128, 0])\n",
    "        ksize = trial.suggest_categorical(\"kernel_size\", [3, 5])\n",
    "\n",
    "        fc1_size = trial.suggest_categorical(\"fc1_size\", [512])\n",
    "        fc2_size = trial.suggest_categorical(\"fc2_size\", [256])\n",
    "        fc3_size = trial.suggest_categorical(\"fc3_size\", [0])\n",
    "        \n",
    "        dropout1 = trial.suggest_float(\"dropout1\", 0.2, 0.5)\n",
    "        dropout2 = trial.suggest_float(\"dropout2\", 0.2, 0.5)\n",
    "        dropout3 = trial.suggest_float(\"dropout3\", 0.2, 0.5)\n",
    "        \n",
    "        self.learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-3, log=True)\n",
    "        \n",
    "        act_fn = nn.LeakyReLU(0.05)\n",
    "        \n",
    "        # Layers\n",
    "        conv_layers = [\n",
    "            nn.Conv2d(3, c1, kernel_size=ksize, padding=ksize // 2),\n",
    "            nn.BatchNorm2d(c1),\n",
    "            act_fn,\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(c1, c2, kernel_size=ksize, padding=ksize // 2),\n",
    "            nn.BatchNorm2d(c2),\n",
    "            act_fn,\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(c2, c3, kernel_size=ksize, padding=ksize // 2),\n",
    "            nn.BatchNorm2d(c3),\n",
    "            act_fn,\n",
    "            nn.MaxPool2d(2),\n",
    "        ]\n",
    "        \n",
    "        # Optionally add conv4\n",
    "        if c4 > 0:\n",
    "            conv_layers.extend([\n",
    "                nn.Conv2d(c3, c4, kernel_size=ksize, padding=ksize // 2),\n",
    "                nn.BatchNorm2d(c4),\n",
    "                act_fn,\n",
    "                nn.MaxPool2d(2),\n",
    "            ])\n",
    "            conv_out = c4\n",
    "        else:\n",
    "            conv_out = c3\n",
    "        \n",
    "        # Add flatten after convs\n",
    "        conv_layers.append(nn.Flatten())\n",
    "        \n",
    "        # Wrap as Sequential\n",
    "        self.model = nn.Sequential(*conv_layers)\n",
    "        \n",
    "        \n",
    "        # Use dummy input to calculate flattened output size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
    "            n_features = self.model(dummy_input).shape[1]\n",
    "        \n",
    "        layers = [\n",
    "            nn.Linear(n_features, fc1_size),\n",
    "            nn.BatchNorm1d(fc1_size),\n",
    "            act_fn,\n",
    "            nn.Dropout(dropout1),\n",
    "        ]\n",
    "\n",
    "        final_in = fc1_size\n",
    "\n",
    "        if fc2_size > 0:\n",
    "            layers.extend([\n",
    "                nn.Linear(fc1_size, fc2_size),\n",
    "                nn.BatchNorm1d(fc2_size),\n",
    "                act_fn,\n",
    "                nn.Dropout(dropout2)\n",
    "            ])\n",
    "            final_in = fc2_size\n",
    "\n",
    "        if fc3_size > 0:\n",
    "            layers.extend([\n",
    "                nn.Linear(final_in, fc3_size),\n",
    "                nn.BatchNorm1d(fc3_size),\n",
    "                act_fn,\n",
    "                nn.Dropout(dropout3)\n",
    "            ])\n",
    "            final_in = fc3_size\n",
    "\n",
    "        self.head = nn.Sequential(*layers)\n",
    "        self.output = nn.Linear(final_in, num_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.head(x)\n",
    "        return self.output(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the Validation DataLoader progress bar between epochs\n",
    "class MinimalProgressBar(TQDMProgressBar):\n",
    "    def init_validation_tqdm(self):\n",
    "        # Return a dummy tqdm with no visible output to disable validation progress bar\n",
    "        # Set total=0 to avoid progress display\n",
    "        return tqdm(disable=True)\n",
    "\n",
    "    def init_test_tqdm(self):\n",
    "        # Same for test dataloader\n",
    "        return tqdm(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearCacheCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedPruningCallback(PyTorchLightningPruningCallback, Callback):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # Only start pruning after 3 epochs\n",
    "        if trainer.current_epoch < 2:\n",
    "            return  # Skip pruning\n",
    "\n",
    "        # Call the original pruning logic\n",
    "        super().on_validation_end(trainer, pl_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    try:\n",
    "        model = CNNModel(trial)\n",
    "        datamodule = DataModule(root_dir=path, batch_size=32, transform=transform)\n",
    "        datamodule.setup()\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            logger=False,\n",
    "            max_epochs=15,\n",
    "            enable_checkpointing=False,\n",
    "            callbacks=[MinimalProgressBar(), \n",
    "                       FixedPruningCallback(trial, monitor=\"val_loss\"),\n",
    "                       ClearCacheCallback()],\n",
    "        )\n",
    "        \n",
    "        trainer.fit(model, datamodule)\n",
    "        return trainer.callback_metrics[\"val_loss\"].item()\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        if \"DefaultCPUAllocator\" in str(e) or \"out of memory\" in str(e):\n",
    "            print(f\"Trial {trial.number} failed due to memory error.\")\n",
    "            return float('inf')\n",
    "        raise  e\n",
    "    \n",
    "    finally:\n",
    "        if 'model' in locals():\n",
    "            del model\n",
    "        if 'trainer' in locals():\n",
    "            del trainer\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 14:26:58,392] A new study created in memory with name: no-name-280c5c2e-b987-442a-b195-0ca1f662dfaf\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 316 K  | train\n",
      "1 | head   | Sequential | 13.0 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "13.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.3 M    Total params\n",
      "53.230    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:21<00:00,  5.32it/s, train_loss=2.000, train_acc=0.438, val_loss=2.170, val_acc=0.398]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:21<00:00,  5.31it/s, train_loss=2.000, train_acc=0.438, val_loss=2.170, val_acc=0.398]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 15:02:57,525] Trial 0 finished with value: 2.1694281101226807 and parameters: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 128, 'kernel_size': 3, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.3526513480130451, 'dropout2': 0.4515211765967886, 'dropout3': 0.2351830722496837, 'learning_rate': 0.0003674188100420839}. Best is trial 0 with value: 2.1694281101226807.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 316 K  | train\n",
      "1 | head   | Sequential | 13.0 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "13.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.3 M    Total params\n",
      "53.230    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:20<00:00,  5.35it/s, train_loss=2.610, train_acc=0.344, val_loss=2.100, val_acc=0.425]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:20<00:00,  5.34it/s, train_loss=2.610, train_acc=0.344, val_loss=2.100, val_acc=0.425]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 15:38:45,192] Trial 1 finished with value: 2.101747751235962 and parameters: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 128, 'kernel_size': 3, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.39574746792575044, 'dropout2': 0.42445898800357507, 'dropout3': 0.31143781629928546, 'learning_rate': 0.0004936522175419208}. Best is trial 1 with value: 2.101747751235962.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 316 K  | train\n",
      "1 | head   | Sequential | 13.0 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "13.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.3 M    Total params\n",
      "53.230    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:19<00:00,  5.37it/s, train_loss=2.310, train_acc=0.344, val_loss=2.100, val_acc=0.423]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:19<00:00,  5.37it/s, train_loss=2.310, train_acc=0.344, val_loss=2.100, val_acc=0.423]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 16:14:29,462] Trial 2 finished with value: 2.0992777347564697 and parameters: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 128, 'kernel_size': 3, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.29052582909653063, 'dropout2': 0.3342236306486829, 'dropout3': 0.34840841032862135, 'learning_rate': 0.0004632153364643866}. Best is trial 2 with value: 2.0992777347564697.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 466 K  | train\n",
      "1 | head   | Sequential | 51.5 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "52.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "52.0 M    Total params\n",
      "207.972   Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:36<00:00,  4.78it/s, train_loss=2.130, train_acc=0.438, val_loss=2.310, val_acc=0.371]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:37<00:00,  4.77it/s, train_loss=2.130, train_acc=0.438, val_loss=2.310, val_acc=0.371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 16:54:10,256] Trial 3 finished with value: 2.307535409927368 and parameters: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 0, 'kernel_size': 5, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.210032093430855, 'dropout2': 0.44888417232129874, 'dropout3': 0.3357748630896292, 'learning_rate': 0.0004963560749658938}. Best is trial 2 with value: 2.0992777347564697.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 876 K  | train\n",
      "1 | head   | Sequential | 13.0 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "13.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.9 M    Total params\n",
      "55.471    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:33<00:00,  4.88it/s, train_loss=2.460, train_acc=0.281, val_loss=2.200, val_acc=0.403]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████| 750/750 [02:33<00:00,  4.88it/s, train_loss=2.460, train_acc=0.281, val_loss=2.200, val_acc=0.403]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 17:33:04,208] Trial 4 finished with value: 2.198068857192993 and parameters: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 128, 'kernel_size': 5, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.2557415564172411, 'dropout2': 0.38070354576141086, 'dropout3': 0.2514728560483357, 'learning_rate': 0.00018401733020757555}. Best is trial 2 with value: 2.0992777347564697.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 466 K  | train\n",
      "1 | head   | Sequential | 51.5 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "52.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "52.0 M    Total params\n",
      "207.972   Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████| 750/750 [02:38<00:00,  4.73it/s, train_loss=2.780, train_acc=0.250, val_loss=2.960, val_acc=0.240]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 17:41:32,312] Trial 5 pruned. Trial was pruned at epoch 2.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 279 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.238    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████| 750/750 [05:43<00:00,  2.18it/s, train_loss=2.780, train_acc=0.250, val_loss=2.960, val_acc=0.240]\n",
      "Epoch 5: 100%|█████| 750/750 [02:21<00:00,  5.29it/s, train_loss=3.260, train_acc=0.188, val_loss=2.550, val_acc=0.302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 17:56:50,807] Trial 6 pruned. Trial was pruned at epoch 5.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 773 K  | train\n",
      "1 | head   | Sequential | 9.8 M  | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "10.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.6 M    Total params\n",
      "42.216    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████| 750/750 [05:23<00:00,  2.32it/s, train_loss=3.260, train_acc=0.188, val_loss=2.550, val_acc=0.302]\n",
      "Epoch 2: 100%|████| 750/750 [02:30<00:00,  4.98it/s, train_loss=3.110, train_acc=0.0625, val_loss=2.870, val_acc=0.244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 18:05:14,155] Trial 7 pruned. Trial was pruned at epoch 2.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 876 K  | train\n",
      "1 | head   | Sequential | 13.0 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "13.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.9 M    Total params\n",
      "55.471    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████| 750/750 [05:43<00:00,  2.18it/s, train_loss=3.110, train_acc=0.0625, val_loss=2.870, val_acc=0.244]\n",
      "Epoch 3: 100%|█████| 750/750 [02:32<00:00,  4.93it/s, train_loss=2.690, train_acc=0.188, val_loss=2.760, val_acc=0.268]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 18:16:25,049] Trial 8 pruned. Trial was pruned at epoch 3.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model  | Sequential | 316 K  | train\n",
      "1 | head   | Sequential | 13.0 M | train\n",
      "2 | output | Linear     | 12.8 K | train\n",
      "----------------------------------------------\n",
      "13.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.3 M    Total params\n",
      "53.230    Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████| 750/750 [05:30<00:00,  2.27it/s, train_loss=2.690, train_acc=0.188, val_loss=2.760, val_acc=0.268]\n",
      "Epoch 2: 100%|█████| 750/750 [02:26<00:00,  5.14it/s, train_loss=3.060, train_acc=0.250, val_loss=2.860, val_acc=0.259]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 18:24:33,966] Trial 9 pruned. Trial was pruned at epoch 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'conv1_out': 64, 'conv2_out': 96, 'conv3_out': 128, 'conv4_out': 128, 'kernel_size': 3, 'fc1_size': 512, 'fc2_size': 256, 'fc3_size': 0, 'dropout1': 0.29052582909653063, 'dropout2': 0.3342236306486829, 'dropout3': 0.34840841032862135, 'learning_rate': 0.0004632153364643866}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(\"Best trial:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trial data to optuna_trials_log.csv\n"
     ]
    }
   ],
   "source": [
    "# Collect all trials into a list of dicts\n",
    "rows = []\n",
    "for trial in study.trials:\n",
    "    row = {\n",
    "        \"trial_number\": trial.number,\n",
    "        \"value\": trial.value,\n",
    "    }\n",
    "    # Add all hyperparameters\n",
    "    row.update(trial.params)\n",
    "    \n",
    "    # Add intermediate values (e.g., val_loss at each epoch)\n",
    "    for step, intermediate in trial.intermediate_values.items():\n",
    "        row[f\"epoch_{step}_val_loss\"] = intermediate\n",
    "    \n",
    "    rows.append(row)\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"optuna_trials_log_2.csv\", index=False)\n",
    "print(\"Saved trial data to optuna_trials_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_env",
   "language": "python",
   "name": "torch_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
